{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/baitong/pywork/Humpback/Data/'\n",
    "TRAIN = PATH+'train/'\n",
    "TEST = PATH+'test/'\n",
    "LABELS = PATH+'train.csv'\n",
    "BOXES = PATH+'bounding_boxes.csv'\n",
    "MODLE_INIT = PATH+'models/'\n",
    "\n",
    "n_embedding = 256\n",
    "bs = 16\n",
    "ratio = 3\n",
    "sz0 = 192\n",
    "sz = (ratio*sz0,sz0)\n",
    "nw = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(fn):\n",
    "    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n",
    "    if not os.path.exists(fn):\n",
    "        raise OSError('No such file or directory: {}'.format(fn))\n",
    "    elif os.path.isdir(fn):\n",
    "        raise OSError('Is a directory: {}'.format(fn))\n",
    "    else:\n",
    "        try:\n",
    "            im = cv2.imread(str(fn), flags)\n",
    "            if im is None: raise OSError(f'File not recognized by opencv: {fn}')\n",
    "            return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        except Exception as e:\n",
    "            raise OSError('Error handling image at: {}'.format(fn)) from e\n",
    "\n",
    "class Loader():\n",
    "    def __init__(self,path,tfms_g=None, tfms_px=None):\n",
    "        #tfms_g - geometric augmentation (distortion, small rotation, zoom)\n",
    "        #tfms_px - pixel augmentation and flip\n",
    "        self.boxes = pd.read_csv(BOXES).set_index('Image')\n",
    "        self.path = path\n",
    "        self.tfms_g = iaa.Sequential(tfms_g,random_order=False) \\\n",
    "                        if tfms_g is not None else None\n",
    "        self.tfms_px = iaa.Sequential(tfms_px,random_order=False) \\\n",
    "                        if tfms_px is not None else None\n",
    "    def __call__(self, fname):\n",
    "        fname = os.path.basename(fname)\n",
    "        x0,y0,x1,y1 = tuple(self.boxes.loc[fname,['x0','y0','x1','y1']].tolist())\n",
    "        img = open_image(os.path.join(self.path,fname))\n",
    "        if self.tfms_g != None: img = self.tfms_g.augment_image(img)\n",
    "        l1,l0,_ = img.shape\n",
    "        b0,b1 = x1-x0 + 50, y1-y0 + 20 #add extra paddning\n",
    "        b0n,b1n = (b0, b0/ratio) if b0**2/ratio > b1**2*ratio else (b1*ratio, b1)\n",
    "        if b0n > l0: b0n,b1n = l0,b1n*l0/b0n\n",
    "        if b1n > l1: b0n,b1n = b0n*l1/b1n,l1\n",
    "        x0n = (x0 + x1 - b0n)/2\n",
    "        x1n = (x0 + x1 + b0n)/2\n",
    "        y0n = (y0 + y1 - b1n)/2\n",
    "        y1n = (y0 + y1 + b1n)/2\n",
    "        x0n,x1n,y0n,y1n = int(x0n),int(x1n),int(y0n),int(y1n)\n",
    "        if(x0n < 0): x0n,x1n = 0,x1n-x0n\n",
    "        elif(x1n > l0): x0n,x1n = x0n+l0-x1n,l0\n",
    "        if(y0n < 0): y0n,y1n = 0,y1n-y0n\n",
    "        elif(y1n > l1): y0n,y1n = y0n+l1-y1n,l1\n",
    "        img = cv2.resize(img[y0n:y1n,x0n:x1n,:], sz)\n",
    "        if self.tfms_px != None: img = self.tfms_px.augment_image(img)\n",
    "        return img.astype(np.float)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, data, path, transform):\n",
    "        df = data.copy()\n",
    "        counts = Counter(df.Id.values)\n",
    "        df['c'] = df['Id'].apply(lambda x: counts[x])\n",
    "        #in the production runs df.c>1 should be used\n",
    "        fnames = df[(df.c>2) & (df.Id != 'new_whale')].Image.tolist()\n",
    "        df['label'] = df.Id\n",
    "        df.loc[df.c == 1,'label'] = 'new_whale'\n",
    "        df = df.sort_values(by=['c'])\n",
    "        df.label = pd.factorize(df.label)[0]\n",
    "        l1 = 1 + df.label.max()\n",
    "        l2 = len(df[df.label==0])\n",
    "        df.loc[df.label==0,'label'] = range(l1, l1+l2) #assign unique ids\n",
    "        self.labels = df.copy().set_index('Image')\n",
    "        self.names = df.copy().set_index('label')\n",
    "        if path == TRAIN:\n",
    "            #data augmentation: 8 degree rotation, 10% stratch, shear\n",
    "            tfms_g = [iaa.Affine(rotate=(-8, 8),mode='reflect',\n",
    "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, shear=(-8,8))]\n",
    "            #data augmentation: horizontal flip, hue and staturation augmentation,\n",
    "            #gray scale, blur\n",
    "            tfms_px = [iaa.Fliplr(0.5), iaa.AddToHueAndSaturation((-20, 20)),\n",
    "                iaa.Grayscale(alpha=(0.0, 1.0)),iaa.GaussianBlur((0, 1.0))]\n",
    "            self.loader = Loader(path,tfms_g,tfms_px)\n",
    "        else: self.loader = Loader(path)\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        label = self.labels.loc[self.fnames[i],'label']\n",
    "        #random selection of a positive example\n",
    "        for j in range(10): #sometimes loc call fails\n",
    "            try:\n",
    "                names = self.names.loc[label].Image\n",
    "                break\n",
    "            except: None\n",
    "        name_p = names if isinstance(names,str) else \\\n",
    "            random.sample(set(names) - set([self.fnames[i]]),1)[0]\n",
    "        #random selection of a negative example\n",
    "        for j in range(10): #sometimes loc call fails\n",
    "            try:\n",
    "                names = self.names.loc[self.names.index!=label].Image\n",
    "                break\n",
    "            except: None\n",
    "        name_n = names if isinstance(names,str) else names.sample(1).values[0]\n",
    "        imgs = [self.loader(os.path.join(self.path,self.fnames[i])),\n",
    "                self.loader(os.path.join(self.path,name_p)),\n",
    "                self.loader(os.path.join(self.path,name_n)),\n",
    "                label,label,self.labels.loc[name_n,'label']]\n",
    "        return imgs\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        return 0\n",
    "    \n",
    "    def get(self, tfm, x, y):\n",
    "        if tfm is None:\n",
    "            return (*x,0)\n",
    "        else:\n",
    "            x1, y1 = tfm(x[0],x[3])\n",
    "            x2, y2 = tfm(x[1],x[4])\n",
    "            x3, y3 = tfm(x[2],x[5])\n",
    "            #combine all images into one tensor\n",
    "            x = np.stack((x1,x2,x3),0)\n",
    "            return x,(y1,y2,y3)\n",
    "        \n",
    "    def get_names(self,label):\n",
    "        names = []\n",
    "        for j in range(10):\n",
    "            try:\n",
    "                names = self.names.loc[label].Image\n",
    "                break\n",
    "            except: None\n",
    "        return names\n",
    "        \n",
    "    @property\n",
    "    def is_multi(self): return True\n",
    "    @property\n",
    "    def is_reg(self):return True\n",
    "    \n",
    "    def get_c(self): return n_embedding\n",
    "    def get_n(self): return len(self.fnames)\n",
    "    \n",
    "#class for loading an individual images when embedding is computed\n",
    "class FilesDataset_single(FilesDataset):\n",
    "    def __init__(self, data, path, transform):\n",
    "        self.loader = Loader(path)\n",
    "        fnames = os.listdir(path)\n",
    "        super().__init__(fnames, transform, path)\n",
    "        \n",
    "    def get_x(self, i):\n",
    "        return self.loader(os.path.join(self.path,self.fnames[i]))\n",
    "                           \n",
    "    def get_y(self, i):\n",
    "        return 0\n",
    "        \n",
    "    @property\n",
    "    def is_multi(self): return True\n",
    "    @property\n",
    "    def is_reg(self):return True\n",
    "    \n",
    "    def get_c(self): return n_embedding\n",
    "    def get_n(self): return len(self.fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO)\n",
    "    tfms[0].tfms = [tfms[0].tfms[2],tfms[0].tfms[3]]\n",
    "    tfms[1].tfms = [tfms[1].tfms[2],tfms[1].tfms[3]]\n",
    "    df = pd.read_csv(LABELS)\n",
    "    trn_df, val_df = train_test_split(df,test_size=0.2, random_state=42)\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (trn_df,TRAIN), (val_df,TRAIN), tfms)\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = get_data(sz,bs)\n",
    "\n",
    "x,y = next(iter(md.trn_dl))\n",
    "print(x.shape, y[0].shape)\n",
    "\n",
    "def display_imgs(x):\n",
    "    columns = 3\n",
    "    rows = min(bs,16)\n",
    "    fig=plt.figure(figsize=(columns*8, rows*3))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = j+i*columns\n",
    "            fig.add_subplot(rows, columns, idx+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow((x[j][i,:,:,:]*255).astype(np.int))\n",
    "    plt.show()\n",
    "    \n",
    "display_imgs((md.trn_ds.denorm(x[:,0,:,:,:]),md.trn_ds.denorm(x[:,1,:,:,:]),md.trn_ds.denorm(x[:,2,:,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnext50(pretrained=True):\n",
    "    model = resnext_50_32x4d()\n",
    "    name = 'resnext_50_32x4d.pth'\n",
    "    if pretrained:\n",
    "        path = os.path.join(MODLE_INIT,name)\n",
    "        load_model(model, path)\n",
    "    return model\n",
    "\n",
    "class TripletResneXt50(nn.Module):\n",
    "    def __init__(self, pre=True, emb_sz=64, ps=0.5):\n",
    "        super().__init__()\n",
    "        encoder = resnext50(pretrained=pre)\n",
    "        self.cnn = nn.Sequential(encoder[0],encoder[1],nn.ReLU(),encoder[3],\n",
    "                        encoder[4],encoder[5],encoder[6],encoder[7])\n",
    "        self.head = nn.Sequential(AdaptiveConcatPool2d(), Flatten(), nn.Dropout(ps),\n",
    "                        nn.Linear(4096, 512), nn.ReLU(), nn.BatchNorm1d(512),\n",
    "                        nn.Dropout(ps), nn.Linear(512, emb_sz))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1,x2,x3 = x[:,0,:,:,:],x[:,1,:,:,:],x[:,2,:,:,:]\n",
    "        x1 = self.head(self.cnn(x1))\n",
    "        x2 = self.head(self.cnn(x2))\n",
    "        x3 = self.head(self.cnn(x3))\n",
    "        return torch.cat((x1.unsqueeze_(-1),x2.unsqueeze_(-1),x3.unsqueeze_(-1)),dim=-1)\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        return self.head(self.cnn(x))\n",
    "    \n",
    "class ResNeXt50Model():\n",
    "    def __init__(self,pre=True,name='TripletResneXt50',**kwargs):\n",
    "        self.model = to_gpu(TripletResneXt50(pre=True,**kwargs))\n",
    "        self.name = name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        m = self.model.module if isinstance(self.model,FP16) else self.model\n",
    "        if precompute:\n",
    "            return [m.head]\n",
    "        c = children(m.cnn)\n",
    "        return list(split_by_idxs(c,[5])) + [m.head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Contrastive_loss(preds, target, size_average=True, m=10.0):\n",
    "    #matrix of all vs all comparisons\n",
    "    t = torch.cat(target)\n",
    "    sz = t.shape[0]\n",
    "    t1 = t.unsqueeze(1).expand((sz,sz))\n",
    "    t2 = t1.transpose(0,1)\n",
    "    y = t1==t2\n",
    "    \n",
    "    pred = torch.cat((preds[:,:,0], preds[:,:,1], preds[:,:,2]))\n",
    "    half = True if isinstance(pred,torch.cuda.HalfTensor) else False\n",
    "    if half : pred = pred.float()\n",
    "    pred1 = pred.unsqueeze(1).expand((sz,sz,-1))\n",
    "    pred2 = pred1.transpose(0,1)\n",
    "    d = (pred1 - pred2).pow(2).sum(dim=-1)\n",
    "    loss_p = d[y==1]\n",
    "    loss_n = F.relu(m - torch.sqrt(d[y==0]))**2\n",
    "    loss = torch.cat((loss_p,loss_n),0)\n",
    "    loss = loss.mean() if size_average else loss.sum()\n",
    "    if half : pred = pred.half()\n",
    "    return loss\n",
    "\n",
    "def DB_acc(preds, target):\n",
    "    v, p, n = preds[:,:,0], preds[:,:,1], preds[:,:,2]\n",
    "    dp = (p - v).pow(2).sum(dim=1)\n",
    "    dn = (n - v).pow(2).sum(dim=1)\n",
    "    return (dp < dn).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ConvLearner(md,ResNeXt50Model(ps=0.0,emb_sz=n_embedding))\n",
    "learner.opt_fn = optim.Adam\n",
    "learner.clip = 1.0 #gradient clipping\n",
    "learner.crit = Contrastive_loss\n",
    "learner.metrics = [DB_acc]\n",
    "learner #click \"output\" to see details of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    learner.lr_find()\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    learner.fit(lr,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()\n",
    "lrs=np.array([lr/25,lr/5,lr])\n",
    "# learner.half() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    learner.fit(lrs/4,2,cycle_len=1,use_clr=(10,20))\n",
    "    learner.fit(lrs/8,4,cycle_len=2,use_clr=(10,20))\n",
    "    learner.fit(lrs/16,8,cycle_len=2,use_clr=(10,20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(lrs/32,8,cycle_len=2,use_clr=(10,20)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
